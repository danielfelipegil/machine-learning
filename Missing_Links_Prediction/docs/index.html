<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ol.lst-kix_list_1-3{list-style-type:none}ol.lst-kix_list_1-4{list-style-type:none}.lst-kix_list_2-6>li:before{content:"\0025cf  "}.lst-kix_list_2-7>li:before{content:"o  "}ol.lst-kix_list_1-5{list-style-type:none}ol.lst-kix_list_1-6{list-style-type:none}ol.lst-kix_list_1-0{list-style-type:none}.lst-kix_list_2-4>li:before{content:"o  "}.lst-kix_list_2-5>li:before{content:"\0025aa  "}.lst-kix_list_2-8>li:before{content:"\0025aa  "}ol.lst-kix_list_1-1{list-style-type:none}ol.lst-kix_list_1-2{list-style-type:none}.lst-kix_list_1-1>li{counter-increment:lst-ctn-kix_list_1-1}.lst-kix_list_3-0>li:before{content:"-  "}.lst-kix_list_3-1>li:before{content:"o  "}.lst-kix_list_3-2>li:before{content:"\0025aa  "}ul.lst-kix_list_3-7{list-style-type:none}ul.lst-kix_list_3-8{list-style-type:none}ol.lst-kix_list_1-8.start{counter-reset:lst-ctn-kix_list_1-8 0}ul.lst-kix_list_3-1{list-style-type:none}.lst-kix_list_3-5>li:before{content:"\0025aa  "}ul.lst-kix_list_3-2{list-style-type:none}.lst-kix_list_3-4>li:before{content:"o  "}ul.lst-kix_list_3-0{list-style-type:none}ol.lst-kix_list_1-5.start{counter-reset:lst-ctn-kix_list_1-5 0}ol.lst-kix_list_1-7{list-style-type:none}.lst-kix_list_3-3>li:before{content:"\0025cf  "}ul.lst-kix_list_3-5{list-style-type:none}.lst-kix_list_1-7>li{counter-increment:lst-ctn-kix_list_1-7}ol.lst-kix_list_1-8{list-style-type:none}ul.lst-kix_list_3-6{list-style-type:none}ul.lst-kix_list_3-3{list-style-type:none}ul.lst-kix_list_3-4{list-style-type:none}.lst-kix_list_3-8>li:before{content:"\0025aa  "}.lst-kix_list_3-6>li:before{content:"\0025cf  "}.lst-kix_list_3-7>li:before{content:"o  "}ol.lst-kix_list_1-7.start{counter-reset:lst-ctn-kix_list_1-7 0}.lst-kix_list_1-2>li{counter-increment:lst-ctn-kix_list_1-2}.lst-kix_list_1-5>li{counter-increment:lst-ctn-kix_list_1-5}.lst-kix_list_1-8>li{counter-increment:lst-ctn-kix_list_1-8}ol.lst-kix_list_1-4.start{counter-reset:lst-ctn-kix_list_1-4 0}ol.lst-kix_list_1-1.start{counter-reset:lst-ctn-kix_list_1-1 0}.lst-kix_list_1-4>li{counter-increment:lst-ctn-kix_list_1-4}ol.lst-kix_list_1-6.start{counter-reset:lst-ctn-kix_list_1-6 0}ol.lst-kix_list_1-3.start{counter-reset:lst-ctn-kix_list_1-3 0}ul.lst-kix_list_2-8{list-style-type:none}ol.lst-kix_list_1-2.start{counter-reset:lst-ctn-kix_list_1-2 0}ul.lst-kix_list_2-2{list-style-type:none}.lst-kix_list_1-0>li:before{content:"" counter(lst-ctn-kix_list_1-0,decimal) ". "}ul.lst-kix_list_2-3{list-style-type:none}ul.lst-kix_list_2-0{list-style-type:none}ul.lst-kix_list_2-1{list-style-type:none}ul.lst-kix_list_2-6{list-style-type:none}.lst-kix_list_1-1>li:before{content:"" counter(lst-ctn-kix_list_1-0,decimal) "." counter(lst-ctn-kix_list_1-1,decimal) ". "}.lst-kix_list_1-2>li:before{content:"" counter(lst-ctn-kix_list_1-0,decimal) "." counter(lst-ctn-kix_list_1-1,decimal) "." counter(lst-ctn-kix_list_1-2,decimal) ". "}ul.lst-kix_list_2-7{list-style-type:none}ul.lst-kix_list_2-4{list-style-type:none}ul.lst-kix_list_2-5{list-style-type:none}.lst-kix_list_1-3>li:before{content:"" counter(lst-ctn-kix_list_1-0,decimal) "." counter(lst-ctn-kix_list_1-1,decimal) "." counter(lst-ctn-kix_list_1-2,decimal) "." counter(lst-ctn-kix_list_1-3,decimal) ". "}.lst-kix_list_1-4>li:before{content:"" counter(lst-ctn-kix_list_1-0,decimal) "." counter(lst-ctn-kix_list_1-1,decimal) "." counter(lst-ctn-kix_list_1-2,decimal) "." counter(lst-ctn-kix_list_1-3,decimal) "." counter(lst-ctn-kix_list_1-4,decimal) ". "}ol.lst-kix_list_1-0.start{counter-reset:lst-ctn-kix_list_1-0 0}.lst-kix_list_1-0>li{counter-increment:lst-ctn-kix_list_1-0}.lst-kix_list_1-6>li{counter-increment:lst-ctn-kix_list_1-6}.lst-kix_list_1-7>li:before{content:"" counter(lst-ctn-kix_list_1-0,decimal) "." counter(lst-ctn-kix_list_1-1,decimal) "." counter(lst-ctn-kix_list_1-2,decimal) "." counter(lst-ctn-kix_list_1-3,decimal) "." counter(lst-ctn-kix_list_1-4,decimal) "." counter(lst-ctn-kix_list_1-5,decimal) "." counter(lst-ctn-kix_list_1-6,decimal) "." counter(lst-ctn-kix_list_1-7,decimal) ". "}.lst-kix_list_1-3>li{counter-increment:lst-ctn-kix_list_1-3}.lst-kix_list_1-5>li:before{content:"" counter(lst-ctn-kix_list_1-0,decimal) "." counter(lst-ctn-kix_list_1-1,decimal) "." counter(lst-ctn-kix_list_1-2,decimal) "." counter(lst-ctn-kix_list_1-3,decimal) "." counter(lst-ctn-kix_list_1-4,decimal) "." counter(lst-ctn-kix_list_1-5,decimal) ". "}.lst-kix_list_1-6>li:before{content:"" counter(lst-ctn-kix_list_1-0,decimal) "." counter(lst-ctn-kix_list_1-1,decimal) "." counter(lst-ctn-kix_list_1-2,decimal) "." counter(lst-ctn-kix_list_1-3,decimal) "." counter(lst-ctn-kix_list_1-4,decimal) "." counter(lst-ctn-kix_list_1-5,decimal) "." counter(lst-ctn-kix_list_1-6,decimal) ". "}.lst-kix_list_2-0>li:before{content:"-  "}.lst-kix_list_2-1>li:before{content:"o  "}.lst-kix_list_1-8>li:before{content:"" counter(lst-ctn-kix_list_1-0,decimal) "." counter(lst-ctn-kix_list_1-1,decimal) "." counter(lst-ctn-kix_list_1-2,decimal) "." counter(lst-ctn-kix_list_1-3,decimal) "." counter(lst-ctn-kix_list_1-4,decimal) "." counter(lst-ctn-kix_list_1-5,decimal) "." counter(lst-ctn-kix_list_1-6,decimal) "." counter(lst-ctn-kix_list_1-7,decimal) "." counter(lst-ctn-kix_list_1-8,decimal) ". "}.lst-kix_list_2-2>li:before{content:"\0025aa  "}.lst-kix_list_2-3>li:before{content:"\0025cf  "}ol{margin:0;padding:0}table td,table th{padding:0}.c27{border-right-style:solid;padding:0pt 5.4pt 0pt 5.4pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:57.2pt;border-top-color:#000000;border-bottom-style:solid}.c33{border-right-style:solid;padding:0pt 5.4pt 0pt 5.4pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:75.8pt;border-top-color:#000000;border-bottom-style:solid}.c75{border-right-style:solid;padding:0pt 5.4pt 0pt 5.4pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:128.5pt;border-top-color:#000000;border-bottom-style:solid}.c56{border-right-style:solid;padding:0pt 5.4pt 0pt 5.4pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;width:522.8pt;border-top-color:#000000;border-bottom-style:solid}.c20{border-right-style:solid;padding:0pt 5.4pt 0pt 5.4pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:372.4pt;border-top-color:#000000;border-bottom-style:solid}.c4{border-right-style:solid;padding:0pt 5.4pt 0pt 5.4pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:100.1pt;border-top-color:#000000;border-bottom-style:solid}.c25{border-right-style:solid;padding:0pt 5.4pt 0pt 5.4pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:55pt;border-top-color:#000000;border-bottom-style:solid}.c14{border-right-style:solid;padding:0pt 5.4pt 0pt 5.4pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;width:174.3pt;border-top-color:#000000;border-bottom-style:solid}.c30{border-right-style:solid;padding:0pt 5.4pt 0pt 5.4pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:73pt;border-top-color:#000000;border-bottom-style:solid}.c74{border-right-style:solid;padding:0pt 5.4pt 0pt 5.4pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:126.7pt;border-top-color:#000000;border-bottom-style:solid}.c50{border-right-style:solid;padding:0pt 5.4pt 0pt 5.4pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:37.8pt;border-top-color:#000000;border-bottom-style:solid}.c40{border-right-style:solid;padding:0pt 5.4pt 0pt 5.4pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:50pt;border-top-color:#000000;border-bottom-style:solid}.c37{border-right-style:solid;padding:0pt 5.4pt 0pt 5.4pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:104pt;border-top-color:#000000;border-bottom-style:solid}.c82{border-right-style:solid;padding:0pt 5.4pt 0pt 5.4pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:124pt;border-top-color:#000000;border-bottom-style:solid}.c32{border-right-style:solid;padding:0pt 5.4pt 0pt 5.4pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:57.4pt;border-top-color:#000000;border-bottom-style:solid}.c66{border-right-style:solid;padding:0pt 5.4pt 0pt 5.4pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:46.6pt;border-top-color:#000000;border-bottom-style:solid}.c42{border-right-style:solid;padding:0pt 5.4pt 0pt 5.4pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:126.9pt;border-top-color:#000000;border-bottom-style:solid}.c17{border-right-style:solid;padding:0pt 5.4pt 0pt 5.4pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:422.7pt;border-top-color:#000000;border-bottom-style:solid}.c54{border-right-style:solid;padding:0pt 5.4pt 0pt 5.4pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;width:174.2pt;border-top-color:#000000;border-bottom-style:solid}.c47{border-right-style:solid;padding:0pt 5.4pt 0pt 5.4pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:55.2pt;border-top-color:#000000;border-bottom-style:solid}.c78{border-right-style:solid;padding:0pt 5.4pt 0pt 5.4pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:61.2pt;border-top-color:#000000;border-bottom-style:solid}.c41{margin-left:36pt;padding-top:4pt;padding-left:3.6pt;padding-bottom:4pt;line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c8{margin-left:18pt;padding-top:4pt;padding-left:0pt;padding-bottom:4pt;line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c19{margin-left:18pt;padding-top:4pt;padding-left:0pt;padding-bottom:2pt;line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c23{margin-left:22.5pt;padding-top:0pt;text-indent:-13.5pt;padding-bottom:4pt;line-height:1.0;orphans:2;widows:2;text-align:justify}.c51{-webkit-text-decoration-skip:none;color:#000000;font-weight:400;text-decoration:underline;vertical-align:baseline;text-decoration-skip-ink:none;font-size:11pt;font-family:"Times New Roman"}.c2{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Times New Roman";font-style:normal}.c10{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Times New Roman";font-style:normal}.c12{color:#44546a;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Times New Roman";font-style:italic}.c6{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Times New Roman";font-style:normal}.c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Times New Roman";font-style:normal}.c11{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Times New Roman";font-style:normal}.c44{padding-top:0pt;padding-bottom:4pt;line-height:1.0;orphans:2;widows:2;text-align:justify}.c5{padding-top:0pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:center}.c28{padding-top:0pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c29{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9.5pt;font-family:"Times New Roman"}.c38{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-family:"Times New Roman";font-style:normal}.c7{padding-top:0pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:justify}.c57{padding-top:0pt;padding-bottom:2pt;line-height:1.0;orphans:2;widows:2;text-align:center}.c22{color:#538135;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Times New Roman"}.c76{padding-top:0pt;padding-bottom:10pt;line-height:1.0;orphans:2;widows:2;text-align:center}.c1{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:left;height:11pt}.c18{margin-left:-5.4pt;border-spacing:0;border-collapse:collapse;margin-right:auto}.c55{color:#44546a;text-decoration:none;vertical-align:baseline;font-family:"Times New Roman"}.c61{color:#000000;text-decoration:none;vertical-align:baseline;font-family:"Times New Roman"}.c65{color:#ed7d31;text-decoration:none;vertical-align:baseline;font-family:"Times New Roman"}.c46{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#0563c1;text-decoration:underline}.c81{background-color:#ffffff;max-width:523.3pt;padding:36pt 36pt 36pt 36pt}.c73{text-decoration:none;vertical-align:baseline;font-family:"Times New Roman"}.c36{color:#385623;font-weight:700}.c34{margin-left:22.5pt;text-indent:-13.5pt}.c21{padding:0;margin:0}.c68{font-weight:400;font-size:11pt}.c24{color:inherit;text-decoration:inherit}.c31{color:#4472c4;font-size:9pt}.c45{height:11pt}.c59{height:97pt}.c26{height:0pt}.c43{font-style:normal}.c48{height:29pt}.c80{vertical-align:super}.c79{height:17pt}.c35{font-size:9pt}.c71{page-break-after:avoid}.c69{font-weight:400}.c9{height:2pt}.c13{height:37pt}.c83{height:107pt}.c63{height:45pt}.c84{height:15pt}.c58{height:31pt}.c67{color:#000000}.c39{font-weight:700}.c64{height:1pt}.c3{height:12pt}.c70{font-size:10.5pt}.c77{height:23pt}.c53{height:30pt}.c62{height:8pt}.c16{font-style:italic}.c49{color:#385623}.c60{height:26pt}.c52{height:10pt}.c15{font-size:10pt}.c72{height:54pt}.title{padding-top:24pt;color:#000000;font-weight:700;font-size:36pt;padding-bottom:6pt;font-family:"Times New Roman";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:justify}.subtitle{padding-top:18pt;color:#666666;font-size:24pt;padding-bottom:4pt;font-family:"Georgia";line-height:1.0;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:justify}li{color:#000000;font-size:11pt;font-family:"Times New Roman"}p{margin:0;color:#000000;font-size:11pt;font-family:"Times New Roman"}h1{padding-top:4pt;color:#000000;font-weight:700;font-size:11pt;padding-bottom:4pt;font-family:"Times New Roman";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:4pt;color:#000000;font-size:11pt;padding-bottom:4pt;font-family:"Times New Roman";line-height:1.0;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}h3{padding-top:4pt;color:#000000;font-size:11pt;padding-bottom:4pt;font-family:"Times New Roman";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:12pt;color:#000000;font-weight:700;font-size:12pt;padding-bottom:2pt;font-family:"Times New Roman";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:justify}h5{padding-top:11pt;color:#000000;font-weight:700;font-size:11pt;padding-bottom:2pt;font-family:"Times New Roman";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:justify}h6{padding-top:10pt;color:#000000;font-weight:700;font-size:10pt;padding-bottom:2pt;font-family:"Times New Roman";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:justify}</style></head><body class="c81"><p class="c44 c45"><span class="c0"></span></p><a id="t.e3fa0eeed7f3b917edd7f3bcf69da650d5253b1b"></a><a id="t.0"></a><table class="c18"><tbody><tr class="c26"><td class="c56" colspan="3" rowspan="1"><p class="c5"><span class="c11">Missing Link Prediction on Observed Twitter Network</span></p></td></tr><tr class="c13"><td class="c54" colspan="1" rowspan="1"><p class="c5"><span class="c2">Kazi Abir Adnan</span></p><p class="c5"><span class="c0">Student ID: 940406</span></p><p class="c5"><span class="c46"><a class="c24" href="mailto:kanan@student.unimelb.edu.au">kanan@student.unimelb.edu.au</a></span></p><p class="c5"><span class="c0">Kaggle ID: kadnan</span></p></td><td class="c54" colspan="1" rowspan="1"><p class="c5"><span class="c2">Daniel Gil</span></p><p class="c5"><span class="c67">Student ID: 905923</span></p><p class="c5"><span class="c46"><a class="c24" href="mailto:gild@student.unimelb.edu.au">gild@student.unimelb.edu.au</a></span></p><p class="c5"><span class="c0">Kaggle ID: gild2018</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c5 c45"><span class="c0"></span></p></td></tr></tbody></table><ol class="c21 lst-kix_list_1-0 start" start="1"><li class="c8"><h1 style="display:inline"><span class="c2">INTRODUCTION</span></h1></li></ol><p class="c44"><span class="c0">The aim of the project is to predict missing edges of a network. The training network is a partial crawl of the Twitter social network. The task is whether edges exist among test node pairs given the network in a Kaggle class competition.</span></p><ol class="c21 lst-kix_list_1-0" start="2"><li class="c8"><h1 style="display:inline"><span class="c2">PROBLEM DEFINITION</span></h1></li></ol><p class="c44"><span>We now formalize the problem of predicting missing links. The network can be represented as a directed graph, </span><img src="images/image1.png"><span>&nbsp;with an edge </span><img src="images/image2.png"><span>&nbsp;indicating that a twitter user called source, </span><img src="images/image3.png"><span>&nbsp;is following another user called sink, </span><img src="images/image4.png"><span>. The input to our prediction problem is the graph </span><img src="images/image5.png"><span>and a node pair </span><img src="images/image6.png"><span>&nbsp;and the task is to predict if each of those test edges </span><img src="images/image7.png"><span class="c0">&nbsp;are true or fake edges in the network.</span></p><ol class="c21 lst-kix_list_1-0" start="3"><li class="c8"><h1 style="display:inline"><span class="c2">DATASET</span></h1></li></ol><p class="c44"><span>The training network is a directed graph which has ~5 million nodes and ~25 million edges (created using </span><span class="c16">networkx</span><span>&nbsp;[1]). The test data is a list of 2,000 edges where 1,000&rsquo;s are real and withheld from the network, while the others fake. The distribution of source out degree falls below 3</span><span class="c80">rd</span><span class="c0">&nbsp;quantile and we define it as low profile that the interaction is fewer compared to the observed graph. In addition, more than 75% of the sinks&rsquo; out degree in testing dataset are 0.</span></p><ol class="c21 lst-kix_list_1-0" start="4"><li class="c8"><h1 style="display:inline"><span class="c2">METHODOLOGY</span></h1></li></ol><p class="c44"><span class="c0">Our strategy is to learn a binary classifier where true edges are positive samples and we need to inject some fake edges to train our model on negative samples. We will use the learned model to predict the missing links not observed on the network. As described earlier, the mean out degree of source nodes is shifted to low profile nodes, our strategy is to learn a model on a dataset which is representative of testing dataset.</span></p><ol class="c21 lst-kix_list_1-1 start" start="1"><li class="c41"><h2 style="display:inline"><span class="c61 c16 c68">TRAINING DATASET PREPARATION</span></h2></li></ol><p class="c44"><span>The training graph has around 25 million true edges which are our positive samples. We know for </span><img src="images/image8.png"><span>&nbsp;nodes on a directed graph, there can be </span><img src="images/image9.png"><span class="c0">&nbsp;combination of edges. In our case, we have only 25 million edges and the rest can be defined as fake. The primary goal is to predict missing links which may seem to contradict the strategy to create fake edges. But, we don&rsquo;t create fake edges of given test pairs. The target is to create similar training dataset which is representative of test dataset so that our model can distinguish between true and fake edges of given test node pairs.</span></p><p class="c44"><span>First, we created true edges from the training graph considering only the nodes present on the test dataset. For example, for a given test node pair </span><img src="images/image6.png"><span>&nbsp;we take node </span><img src="images/image10.png"><span>&nbsp;and select </span><img src="images/image8.png"><span>&nbsp;sinks from its followees which have similar in degree and page rank of </span><img src="images/image11.png"><span>. Then, we take sink </span><img src="images/image11.png"><span>&nbsp;and select </span><img src="images/image8.png"><span>&nbsp;source nodes from its followers which have similar out degree and page rank of source &nbsp;</span><img src="images/image10.png"><span>. Therefore, for a given test pair we sample </span><img src="images/image12.png"><span>&nbsp;edges from network based on degree and page rank score of given pairs. In case degrees are fewer than the number (</span><img src="images/image8.png"><span>) or the page rank does not match, then we only take the neighboring nodes of </span><img src="images/image10.png"><span>or </span><img src="images/image11.png"><span>. To create fake edges, we select </span><img src="images/image10.png"><span>&nbsp;and randomly sample </span><img src="images/image8.png"><span>&nbsp;sink nodes which has similar degree and page rank like </span><img src="images/image11.png"><span>, we took similar approach for sink </span><img src="images/image11.png"><span>. If the degree of nodes does not match we set the </span><img src="images/image8.png"><span class="c0">&nbsp;according to &ldquo;in&rdquo; or &ldquo;out degree&rdquo; respective to sink and source. We do not create fake edges of test node pairs.</span></p><a id="t.5c5d32c3eb1e47c96695225d44a274c77403b988"></a><a id="t.1"></a><table class="c18"><tbody><tr class="c83"><td class="c74" colspan="1" rowspan="1"><p class="c7"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 147.80px; height: 133.80px;"><img alt="" src="images/image17.png" style="width: 147.80px; height: 133.80px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td><td class="c82" colspan="1" rowspan="1"><p class="c7"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 144.87px; height: 132.67px;"><img alt="" src="images/image20.png" style="width: 144.87px; height: 132.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td><td class="c75" colspan="1" rowspan="1"><p class="c7"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 147.80px; height: 133.80px;"><img alt="" src="images/image18.png" style="width: 147.80px; height: 133.80px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td><td class="c42" colspan="1" rowspan="1"><p class="c7"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 146.60px; height: 132.67px;"><img alt="" src="images/image22.png" style="width: 146.60px; height: 132.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr><tr class="c59"><td class="c74" colspan="1" rowspan="1"><p class="c7"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 150.67px; height: 135.00px;"><img alt="" src="images/image21.png" style="width: 150.67px; height: 135.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td><td class="c82" colspan="1" rowspan="1"><p class="c7"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 143.73px; height: 132.07px;"><img alt="" src="images/image15.png" style="width: 143.73px; height: 132.07px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td><td class="c75" colspan="1" rowspan="1"><p class="c7"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 150.67px; height: 135.00px;"><img alt="" src="images/image14.png" style="width: 150.67px; height: 135.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td><td class="c42" colspan="1" rowspan="1"><p class="c7 c71"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 148.93px; height: 132.07px;"><img alt="" src="images/image16.png" style="width: 148.93px; height: 132.07px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr></tbody></table><p class="c76"><span class="c55 c35 c39 c16">Table 1:Degree, Page Rank, common followers and common followees distribution of original (</span><span class="c16 c22">Green</span><span class="c55 c35 c39 c16">), fake (</span><span class="c35 c39 c16 c65">Orange</span><span class="c55 c35 c39 c16">) and test (</span><span class="c31 c39 c16 c73">blue</span><span class="c35 c39 c16 c55">) dataset</span></p><ol class="c21 lst-kix_list_1-1" start="2"><li class="c41"><h2 style="display:inline"><span class="c61 c68 c16">FEATURE LEARNING</span></h2></li></ol><a id="t.f198ef29bcb26c0a169f41d51fec2671ae50cbfd"></a><a id="t.2"></a><table class="c18"><tbody><tr class="c84"><td class="c66" colspan="1" rowspan="1"><p class="c7"><span class="c6">Degree ratios[2]</span></p></td><td class="c30" colspan="1" rowspan="1"><p class="c7"><span class="c6">Mutual neighbors[2]</span></p></td><td class="c40" colspan="1" rowspan="1"><p class="c7"><span class="c6">Follow back</span></p></td><td class="c78" colspan="1" rowspan="1"><p class="c7"><span class="c6">Triadic </span></p><p class="c7"><span class="c6">closure</span></p></td><td class="c27" colspan="1" rowspan="1"><p class="c7"><span class="c6">Node </span></p><p class="c7"><span class="c6">Page rank[3]</span></p></td><td class="c33" colspan="1" rowspan="1"><p class="c7"><span class="c6">Jaccard&rsquo;s coefficient[2]</span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c7"><span class="c6">Adamic/ Adar[3]</span></p></td><td class="c37" colspan="1" rowspan="1"><p class="c7"><span class="c6">Preferential attachment[3]</span></p></td></tr><tr class="c26"><td class="c66" colspan="1" rowspan="1"><p class="c28"><span class="c6">In Degree</span></p><p class="c28"><span class="c6">Out Degree</span></p><p class="c28"><span class="c6">In ratio/ out ratio</span></p></td><td class="c30" colspan="1" rowspan="1"><p class="c28"><span class="c6">Sum of common follower &amp; followees</span></p></td><td class="c40" colspan="1" rowspan="1"><p class="c28"><span class="c6">Sink follows back source?</span></p></td><td class="c78" colspan="1" rowspan="1"><p class="c28"><span class="c6"># of source followees follows sink</span></p></td><td class="c27" colspan="1" rowspan="1"><p class="c28"><span class="c6">Quality of node &amp; quantity of links</span></p></td><td class="c33" colspan="1" rowspan="1"><p class="c28"><span class="c6">similarity measure of mutual neighbors</span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c28"><span class="c6">similarity between nodes</span></p></td><td class="c37" colspan="1" rowspan="1"><p class="c28 c71"><span class="c6">probability that an edge forms with a specific node is prop. &nbsp;to its existing indegree</span></p></td></tr></tbody></table><p class="c57"><span class="c12">Table 2: We have calculated several features mostly topological and link prediction based to represent a node pair (edge)</span></p><ol class="c21 lst-kix_list_1-1" start="3"><li class="c41"><h2 style="display:inline"><span class="c61 c68 c16">MODEL LEARNING</span></h2></li></ol><p class="c44"><span class="c0">We will use traditional binary classifiers to predict edges and described in detail on the following section. It is important to note, we used 0 and 1 instead of prediction probabilities to analyze model&rsquo;s contingency table for experiments.</span></p><ol class="c21 lst-kix_list_1-0" start="5"><li class="c8"><h1 style="display:inline"><span class="c2">EXPERIMENTS</span></h1></li></ol><a id="t.fde054e92ae7e1a9ae9fbec5f0cf0d070bcdaee1"></a><a id="t.3"></a><table class="c18"><tbody><tr class="c48"><td class="c17" colspan="1" rowspan="1"><p class="c5"><span class="c10">Experiments &amp; Dataset</span></p><p class="c28"><span class="c61 c35 c16 c69">This table represents chronological ordering of experiments. The first row represents the first experiment after we have created the dataset. And the last row in the table represents the one selected on Kaggle as the best one</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c28"><span class="c10">[Model, Validation AUC, # of Positives on test data, Kaggle AUC]</span></p></td></tr><tr class="c26"><td class="c17" colspan="1" rowspan="2"><p class="c7"><span class="c6">We started only with edges and nodes involving test data nodes (3,948) and ended with 63,472 true edges. Then we randomly created 63,472 node pairs from nodes in test data and created fake edges (excluding pairs in test set).</span></p><p class="c7"><span class="c10">[Samples: ~125k (50% pos), Feature Size: 6 Features: In &amp; out Degree, common followers &amp; Followees]</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c6">[LR, 0.88, 805 ,0.80]</span></p></td></tr><tr class="c26"><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c6">[RF, 0.93, 424, 0.71]</span></p></td></tr><tr class="c62"><td class="c17" colspan="1" rowspan="2"><p class="c7"><span class="c6">We added feature whether sink follows back source. We also counted triadic closure which counts how many of source followees follow sink. We also created a graph out of 3948 test nodes using the edges from train data and calculated largest strongly connected component (SCC) and created four category of edges which represents source or sinks presence in SCC (1,2,3,4)</span></p><p class="c7"><span class="c10">[Samples: ~125k (50% pos), Feature Size: 9 Features: + Followback, +Triadicclosure, + SCC]</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c6">[LR, 0.91, 304, 0.65]</span></p></td></tr><tr class="c62"><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c6">[RF, 0.95, 516, 0.72]</span></p></td></tr><tr class="c62"><td class="c17" colspan="1" rowspan="2"><p class="c7"><span class="c6">Since 88% nodes on created graph from previous experiment belong to largest SCC. The SCC value distribution is (Source and sink both in SCC (1): 0.2, Source in SCC &amp; Sink out (2): 0.7, source out of SCC (3): &nbsp;0.03, source &amp; sink out of SCC (4): 0.07). We created 4 separate models for each category and Kaggle AUC improved by 0.03. Though it improved, the score on Kaggle but has a big limitation.</span></p><p class="c7"><span class="c10">[Samples: ~125k (50% pos), Feature Size: Different for each SCC type (-) SCC &amp; (-) Followback for 2, 3]</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c6">[LR, 1: 0.87 2: 0.92 3: 0.78 4: 0.83, 920, 0.80]</span></p></td></tr><tr class="c62"><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c6">[RF, 1: 0.92 2: 0.93 3: 0.90 4: 0.80, 573, 0.77]</span></p></td></tr><tr class="c72"><td class="c17" colspan="1" rowspan="1"><p class="c7"><span class="c6">The experiment showed SSC was not suitable as we have missing links in Graph which lead to different structures. We then moved to one class methods. The intuition was to learn One Class SVM to detect fake edges as anomalies. The model on validation test mostly distinguished fake ones. But, when we used the model on test data it predicted more than 80% as fake. Then, we got rid of fake edges and learn only true edges imputing 1% fakes on training set and predicted all test edges fake.</span></p><p class="c7"><span class="c10">[Samples: ~125k (50% pos), Feature Size: 9, Same Features as previous experiment]</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c6">[One Class SVM, NA, 1: 120 2: 0, N/A]</span></p></td></tr><tr class="c53"><td class="c17" colspan="1" rowspan="1"><p class="c7"><span class="c6">At this stage, we thought to use clustering as the test data contains 50% of fake and original edges. Our idea was to create two cluster of edges which might represent true and fake edge clusters. We used KMeans with parameter K = 2 with the same features. Unfortunately, we ended up with a single cluster with all 2000 test edges.</span></p><p class="c7"><span class="c10">[Samples: Test data, Feature Size: 9, Same Features as previous experiment]</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c6">[KMeans, NA, 0, 0.5]</span></p></td></tr><tr class="c77"><td class="c17" colspan="1" rowspan="2"><p class="c7"><span class="c6">A flaw was found in true training data sampling using distribution of test data. We found fake edges of training set was representing the same distribution as test data. But, the feature distribution was very different for true edges. The dataset we created are good for high profile nodes edges and does not represent the testing dataset. As a result, we created new training dataset for true edges not confining only to test nodes. We sampled more true edges fixing source node from test dataset and added more sinks from original graph. The fake edges only involved test nodes and sampled more. The intuition was as the distribution for fake edge features represents test data we were safe which was indeed another mistake.</span></p><p class="c7"><span class="c10">[Samples: 200k (50% pos) Feature Size: 11, Features: (+) Page Rank of source and sink]</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c6">[LR, 0.91, 429, 0.75]</span></p></td></tr><tr class="c63"><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c6">[RF, 0.93, 240, 0.67]</span></p></td></tr><tr class="c52"><td class="c17" colspan="1" rowspan="2"><p class="c7"><span class="c6">The only difference in this experiment is we fixed sink and sampled source node from original graph. The intuition was as our task is to predict follow relationship, so it is better to focus more on sinks rather sources.</span></p><p class="c7"><span class="c10">[Samples: 200K (50% pos), Feature Size: 11]</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c6">[LR, ~, ~, ~ ]</span></p></td></tr><tr class="c9"><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c6">[RF, ~, ~. ~]</span></p></td></tr><tr class="c60"><td class="c17" colspan="1" rowspan="2"><p class="c7"><span class="c6">We realized the sampling method for creating true edge dataset was enough wrong. We need to create true edges where source&rsquo;s out degree is low. If we see the distribution of source out degree&rsquo;s in test dataset we can see 75% of edges have out degree less than 500. Therefore, we improved the sampling method by adding constraints. We tried to sample nodes both for sinks and sources based on page rank. We sampled edges where for both source and sink has similar page rank for each node pair of test nodes. This seemed to be reasonable and the distribution seemed very similar to testing dataset (Table 1). We focused more to low profile nodes as they are 75% of test data.</span></p><p class="c7"><span class="c10">[Samples: 60K (50% pos) Feature Size: 11]</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c6">[LR, 0.52, N/A, N/A]</span></p></td></tr><tr class="c63"><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c6">[RF, 0.84, 640, 0.81]</span></p></td></tr><tr class="c9"><td class="c17" colspan="1" rowspan="2"><p class="c28"><span class="c35">Our last experiment performed similar on both Kaggle and validation set. That motivated us to sample more edges and created new training dataset. We also expanded our feature set by adding link prediction-based features. </span><span class="c35 c39">[Samples: 120K (50% pos), Feature Size: 15 Features: (+) Degree ratio (+) Jaccard (+) Adamic (+) Preferential attachment]</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c6">[LR, 0.54, N/A, N/A]</span></p></td></tr><tr class="c64"><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c31">[</span><span class="c31 c39">RF</span><span class="c31">, 0.88, 729, 0.</span><span class="c31 c39">85</span><span class="c31">]</span></p></td></tr><tr class="c79"><td class="c17" colspan="1" rowspan="1"><p class="c7"><span class="c6">We added another constraint of degree matching along with page rank and used Multilayer Perceptron Classifier to learn a non-linear model. We trained the model using &lsquo;relu&rsquo;, &lsquo;tanh&rsquo; activation function and different hidden layer sizes to tune it and got some consistent result. We analyzed results against confusion matrix to select what we considered to perform better with the 100% dataset in Kaggle.</span></p><p class="c7"><span class="c10">[Samples: 300K (50% pos), Same Features]</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c7 c71"><span class="c35 c49">[</span><span class="c36 c35">MLP</span><span class="c35 c49">, 0.85, 865, </span><span class="c35 c36">0.853</span><span class="c35 c49">]</span></p></td></tr></tbody></table><p class="c57"><span class="c12">Table 3 : Chronological ordering of our experiments. Here in table LR: Logistic Regression, RF: Random Forest, MLP: Multilayer Perceptron</span></p><p class="c44"><span class="c0">We have tried KNN, Adaboost Classifier, Gaussian Process Classifier SVM, Decision tree classifier. But, the performance is not good as MLP, RF or LR.</span></p><ol class="c21 lst-kix_list_1-0" start="6"><li class="c8"><h1 style="display:inline"><span class="c2">MODEL SELECTION, FEATURE SELECTION &amp; PARAMETER TUNING</span></h1></li></ol><p class="c44"><span class="c0">The final dataset has around ~145K positive and ~145K negative samples and both Random Forest and Multilayer Perceptron (MLP) provided prominent result. We split our training dataset for validation (0.2%). As MLP is sensitive to feature values we normalized features. We tried to use PCA to reduce the dimension of feature. But, the first two principal components explain 99.5% variance and didn&rsquo;t provide any insights. The features are created from adjacency matrix and can be explained in most prominent PC&rsquo;s. We used several feature selection methods during training though, the performance didn&rsquo;t improve. </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 268.27px; height: 183.60px;"><img alt="" src="images/image19.png" style="width: 268.27px; height: 183.60px; margin-left: -0.00px; margin-top: -0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c44" id="h.gjdgxs"><span>We then focused to parameter tuning of the models using grid search method. We took sample of training data to tune the model as dataset is very large which takes time to do grid searching. For Random Forest we tried to tune max samples on leaf, depth of tree and other parameters using cross validation. For MLP we tried different activation functions, layers and neurons combination and finally selected the hidden layer equal to feature numbers and &lsquo;</span><span class="c16">relu</span><span class="c0">&rsquo; activation. The final selection was in between RF and MLP. We have chosen these two different models as RF is ensembled Decision Tree based method and MLP can learn a non-linear classifier. We finally selected the result of MLP. Because, the average performance of MLP was consistent on cross-validation. In our validation set the final AUC was 0.96 and Kaggle AUC was 0.913. On the other hand, Random Forest overfitted on training data as (AUC .97 on validation) but on Kaggle it plunged to 0.851.</span></p><ol class="c21 lst-kix_list_1-0" start="7"><li class="c8"><h1 style="display:inline"><span class="c2">FINAL RESULTS</span></h1></li></ol><a id="t.78a80a5b27283ac684a17cccd63479a6e4e6422b"></a><a id="t.4"></a><table class="c18"><tbody><tr class="c3"><td class="c20" colspan="1" rowspan="1"><p class="c5"><span class="c10">Training Dataset</span></p></td><td class="c47" colspan="1" rowspan="1"><p class="c5"><span class="c10">Model</span></p></td><td class="c32" colspan="1" rowspan="1"><p class="c5"><span class="c10">AUC (Validation)</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c5"><span class="c10">Kaggle AUC</span></p></td></tr><tr class="c26"><td class="c20" colspan="1" rowspan="3"><p class="c7"><span class="c61 c43 c39 c15">Original: ~145K, Fake: ~145K</span></p><p class="c7"><span class="c43 c39 c15 c61">Feature Size: 15, Sampling constraint: Page Rank &amp; Degree of nodes </span></p><p class="c7"><span class="c15 c39">Process</span><span class="c15">: Take each node pair </span><img src="images/image13.png"><span class="c15">&nbsp;of test set (2000) and sample 50 sources from the followers of </span><img src="images/image11.png"><span class="c15">&nbsp;who has similar degree and page rank like source </span><img src="images/image10.png"><span class="c15">&nbsp;and again sample 50 sinks from followees of </span><img src="images/image10.png"><span class="c15">who has similar degree and page rank like </span><img src="images/image10.png"><span class="c38 c15">. If any node has fewer degree than 50 or constraints don&rsquo;t match, then select nodes equal to the degree. For fake edges we followed similar process but, instead of selecting neighbors we randomly selected nodes from graph with the sampling constraint on page rank and degree.</span></p></td><td class="c47" colspan="1" rowspan="1"><p class="c7"><span class="c38 c15">Random Forest</span></p></td><td class="c32" colspan="1" rowspan="1"><p class="c7"><span class="c38 c15">0.95</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c7"><span class="c15 c38">0.851</span></p></td></tr><tr class="c26"><td class="c47" colspan="1" rowspan="1"><p class="c7"><span class="c38 c15">MLP</span></p></td><td class="c32" colspan="1" rowspan="1"><p class="c7"><span class="c38 c15">0.96</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c7"><span class="c38 c15">0.913</span></p></td></tr><tr class="c58"><td class="c47" colspan="1" rowspan="1"><p class="c7"><span class="c38 c15">Logistic Regression</span></p></td><td class="c32" colspan="1" rowspan="1"><p class="c7"><span class="c38 c15">0.77</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c7"><span class="c38 c15">N/A</span></p></td></tr></tbody></table><p class="c5"><span class="c12">Table 4: Final experiment training dataset and models. We tried to tune the model to get best result and which provided consistent performance</span></p><ol class="c21 lst-kix_list_1-0" start="8"><li class="c8"><h1 style="display:inline"><span class="c2">DISCUSSION</span></h1></li></ol><p class="c44"><span>Our journey to final result is like a path of Gradient Descent algorithm to find the maximum AUC. At the very beginning we faced memory issue and overcame this problem by creating a subgraph containing the test node pairs. At the next step we calculated the degrees of nodes using an efficient data structure to compute necessary features. The method finally we used to sample true and fake edges is not efficient as it creates fewer fake edges for higher degree nodes. We ran out of samples on 4</span><span class="c80">th</span><span class="c0">&nbsp;quantile and it affected our prediction performance for high degree edges. At the modeling stage, we initially learned a model which focused more on high profile nodes with high in degree and out degree for true edges. The analysis on test data feature distribution helped us to focus more on low profile nodes. However, the final model doesn&rsquo;t perform good on higher degree nodes as our models are more focused to low page rank nodes and degree. One thing should be mentioned with great importance is that, until very last moment of competition we submitted 0/1 instead of probability. But, when we submitted the same result with probability our AUC improved by .06. This is because, the prediction was continuous rather we predicted using the extreme values. Coding bugs were like true buddy of us and wasted ample time for feature computation. We could not add more figures due to page limitation which includes model tuning, prediction mismatch region &amp; feature analysis.</span></p><ol class="c21 lst-kix_list_1-0" start="9"><li class="c8"><h1 style="display:inline"><span class="c2">FUTURE IMPROVEMENT</span></h1></li></ol><p class="c44"><span class="c0">The main challenge for the project is to create a good training dataset resembling the testing one. We want to improve our model to make more general for any test dataset. For modeling, we want to learn separate models for high-profile and low-profile nodes. The experiments depict it is very difficult to predict fake edges which involves high degree nodes. Fore feature selection, we want to try deep representation of graph features [4] as we &nbsp;needed more features to improve prediction accuracy. We also want to analyze feature importance which we couldn&rsquo;t due to time constraint.</span></p><ol class="c21 lst-kix_list_1-0" start="10"><li class="c19"><h1 style="display:inline"><span class="c2">REFERENCES</span></h1></li></ol><p class="c7 c34"><span class="c38 c70">1.</span><span class="c29 c43">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Hagberg, A., P. Swart, and D. S Chult, </span><span class="c29 c16">Exploring network structure, dynamics, and function using NetworkX</span><span class="c29 c43">. 2008, Los Alamos National Lab.(LANL), Los Alamos, NM (United States).</span></p><p class="c7 c34"><span class="c29 c43">2.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Cheng, J., et al. </span><span class="c29 c16">Predicting reciprocity in social networks</span><span class="c29 c43">. in </span><span class="c29 c16">Privacy, Security, Risk and Trust (PASSAT) and 2011 IEEE Third Inernational Conference on Social Computing (SocialCom), 2011 IEEE Third International Conference on</span><span class="c29 c43">. 2011. IEEE.</span></p><p class="c7 c34"><span class="c29 c43">3.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Page, L., et al., </span><span class="c29 c16">The PageRank citation ranking: Bringing order to the web</span><span class="c29 c43">. 1999, Stanford InfoLab.</span></p><p class="c23"><span class="c29 c43">4.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Cao, S., W. Lu, and Q. Xu. </span><span class="c16 c29">Deep Neural Networks for Learning Graph Representations</span><span class="c29 c43">. in </span><span class="c29 c16">AAAI</span><span class="c29 c43">. 2016.</span></p><p class="c44 c45"><span class="c0"></span></p></body></html>